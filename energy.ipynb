{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import sqlite3\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we gather ideas what can be done with all the energy load data (industrial3 and residential3,4 seems to be most interesting, they might be studied in more detail):\n",
    "\n",
    "1. Anomaly detection in load (e.g. weekly, daily, hourly), and with a distintion on particular loads\n",
    "2. Typical daily/week consumption (e.g. with an alpha parameter)\n",
    "3. Clustering days and loads\n",
    "4. Analysis of PV data\n",
    "5. Prediction of energy consumption\n",
    "6. Kind of 'heat map' of the hourly consumption through years (plus violin, ridgeline plots)\n",
    "7. Time characteristics of each device's load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to database\n",
    "con = sqlite3.connect(\"household_data.sqlite\")\n",
    "cursor = con.execute('select * from household_data_60min_singleindex')\n",
    "\n",
    "# get all the columns with indices\n",
    "energy_columns = [(i, description[0]) for (i, description) in enumerate(cursor.description)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect labels and indices for particular facilities\n",
    "ind_labels = ['industrial1', 'industrial2', 'industrial3', 'public']\n",
    "res_labels = ['residential{}'.format(i) for i in range(1,7)]\n",
    "labels = ind_labels+res_labels\n",
    "index_list = []\n",
    "for label in labels:\n",
    "    index_list.append([[item[0] for item in energy_columns if bool(re.search(label, item[1]))], \n",
    "                       [item[1] for item in energy_columns if bool(re.search(label, item[1]))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of df's that contain hourly load data for all facilities and perform basic preprocessing\n",
    "df_list = []\n",
    "for i, label in enumerate(labels):\n",
    "    # for each facility we query for respective columns with the join trick\n",
    "    df = pd.read_sql_query('SELECT utc_timestamp, {} FROM household_data_60min_singleindex'.format(\",\".join(index_list[i][1])), con)\n",
    "    df.iloc[:,0] = pd.to_datetime(df.iloc[:,0]) # change timestamp to datetime type\n",
    "    df = df.set_index(df.iloc[:,0]).drop(columns='utc_timestamp') # new index from timestamp\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col+'_diff'] = df[col].diff() # in fact we need load differences that give hourly demand\n",
    "        first_idx = df[col].first_valid_index()\n",
    "        last_idx = df[col].last_valid_index()\n",
    "        df = df.loc[first_idx:last_idx] \n",
    "    df = df.drop(columns=index_list[i][1]) # we can get rid of the incremental columns\n",
    "    \n",
    "    # let's mask anomalies ( > 3*std) with a median\n",
    "    df.iloc[:,1:] = df.iloc[:,1:].mask((df.iloc[:,1:]-df.iloc[:,1:].mean()).abs() > 3*df.iloc[:,1:].std(), \n",
    "                                          other=df.iloc[:,1:].median(), axis=1)\n",
    "    \n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #visualizing all the curves for all facilities\n",
    "# for df in df_list:\n",
    "#     fig = go.Figure()\n",
    "#     for col in df.columns:\n",
    "#         fig.add_trace(go.Scatter(x = df.index,\n",
    "#                                y = df[col],\n",
    "#         #                                  visible='legendonly',\n",
    "#                                name = col))\n",
    "\n",
    "#         # fig[\"layout\"].update({\"xaxis\": {\"tickformat\": \"%H:%M\"}})\n",
    "#     fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the industrial facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's copy df related to e.g. industrial3\n",
    "df_ind = df_list[2].copy()\n",
    "\n",
    "# to visualize load profiles in 3d, we pivot df on date and hour demand\n",
    "df_ind['hour'] = df_ind.index.hour\n",
    "df_ind['date'] = df_ind.index.date\n",
    "for col in df_ind.columns[:-2]:\n",
    "    df_pivot = df_ind.pivot(index='date', columns='hour', values=col)\n",
    "\n",
    "    fig = go.Figure(data=[go.Surface(z=df_pivot.values,\n",
    "                                    y = df_pivot.index,\n",
    "                                    x = df_pivot.columns)])\n",
    "\n",
    "    fig.update_layout(title='Load profiles through the year for {}'.format(col), autosize=True,\n",
    "                      scene = dict(\n",
    "                        xaxis_title='day hour',\n",
    "                        zaxis_title=\"Energy consumed [kWh]\")  \n",
    "                     )\n",
    "\n",
    "    fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the residiential facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's copy df related to e.g. residiential3\n",
    "df_res = df_list[6].copy()\n",
    "df_res['hour'] = df_res.index.hour\n",
    "df_res['date'] = df_res.index.date\n",
    "df_res = df_res.set_index('date')\n",
    "\n",
    "# plain heatmaps with a load profiles, without pivoting\n",
    "for col in df_res[:-2]:\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "            z=df_res[col],\n",
    "            x=df_res.index,\n",
    "            y=df_res.hour))\n",
    "\n",
    "    fig.update_layout(title='load profiles through the year for {}'.format(col))\n",
    "\n",
    "    fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
